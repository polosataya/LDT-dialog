# streamlit run app.py
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
import joblib
from catboost import CatBoostClassifier, Pool
import spacy
import re

st.set_page_config(
    page_title="–ú–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–¥–∞—é—â–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤",
    page_icon="üìù", layout="wide",
    initial_sidebar_state="expanded",
    menu_items={'Get Help': None,'Report a bug': None,'About': None})

hide_streamlit_style = """<style>#MainMenu {visibility: hidden;}footer {visibility: hidden;}</style>"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

############################################################################
# —Ñ—É–Ω–∫—Ü–∏–∏
############################################################################
lemmatizer = spacy.load('ru_core_news_md', disable = ['parser', 'ner'])
stopwords_nltk=[]

def full_clean(s):
    #–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∫ –ø–æ–¥–∞—á–µ –≤ –º–æ–¥–µ–ª—å
    s=re.sub(r"[^a-zA-Z–∞-—è–ê-–Ø–π–ô#]", " ", s)
    s = s.lower()
    s = re.sub(" +", " ", s) #–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 1 –ø—Ä–æ–±–µ–ª
    text = " ".join([token.lemma_ for token in lemmatizer(s) if token.lemma_ not in stopwords_nltk])
    
    return text

def tfidf_featuring(tfidf, df):   
    '''–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –º–µ—à–æ–∫ —Å–ª–æ–≤'''
    X_tfidf = tfidf.transform(df)
    feature_names = tfidf.get_feature_names_out()
    X_tfidf = pd.DataFrame(X_tfidf.toarray(), columns = feature_names, index = df.index)
    
    return X_tfidf

def get_params(data, start, emotional):
    # –Ω–æ–º–µ—Ä –¥–∏a–ª–æ–≥–∞ –∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
    nums=[]
    num = start
    for i, row in data.iterrows():
        if row["‚Ññ —Å–æ–æ–±—â–µ–Ω–∏—è"]==1:
            num+=1
        nums.append(num)
    data['‚Ññ –¥–∏–∞–ª–æ–≥–∞']=nums
    data['emotional']=emotional
    return data

def create_texts(data):
    # —Ç–µ–∫—Å—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    texts=[]
    string = ''
    for i, row in data.iterrows():
        if row["‚Ññ —Å–æ–æ–±—â–µ–Ω–∏—è"]==1:
            if string != '':
                texts.append(string)
                string = str(row["–¢–µ–∫—Å—Ç"])+' '
            else:
                string += str(row["–¢–µ–∫—Å—Ç"])+' '
        else:
            if row["–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ"]=='in':
                string += str(row["–¢–µ–∫—Å—Ç"])+' '
    texts.append(string)
    return texts

@st.cache_data
def load_file(falepath):
    '''–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞'''
    df = pd.read_excel(falepath, engine='openpyxl') #sheet_name='valid', 
    df = get_params(df, 0, "unknow")
    data = df[['‚Ññ –¥–∏–∞–ª–æ–≥–∞', 'emotional']].drop_duplicates()
    data['texts']=create_texts(df)
    data['–æ—Ç–∫–∞–∑ –æ—Ç –ø—Ä–æ–¥—É–∫—Ç–æ–≤']=0
    data['–∂–∞–ª–æ–±—ã']=0
    data['–ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å']=0
    data['–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ']=0
    data['—É—Ç–µ—Ä—è/–∫—Ä–∞–∂–∞ –∫–∞—Ä—Ç—ã']=0
    data['clean'] = data['texts'].apply(lambda x: full_clean(x))
    return df, data

@st.cache_data
def load_tfidf(falepath):
    '''–ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞'''
    tfidf = TfidfVectorizer()
    tfidf = joblib.load(falepath)
    return tfidf

@st.cache_data
def load_model1(falepath):
    '''–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏'''
    model_1 = CatBoostClassifier()
    model_1.load_model(falepath)
    return model_1 

@st.cache_data
def load_model1(falepath):
    '''–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å—Ç–æ–ø —Ç–µ–º'''
    model_2 = CatBoostClassifier()
    model_2.load_model(falepath)
    return model_2

############################################################################
# –∑–∞–≥—Ä—É–∑–∫–∞
############################################################################

stop_theme = ['–æ—Ç–∫–∞–∑ –æ—Ç –ø—Ä–æ–¥—É–∫—Ç–æ–≤', '–∂–∞–ª–æ–±—ã', '–ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω–∞—è –∑–∞–¥–æ–ª–∂–µ–Ω–Ω–æ—Å—Ç—å', '–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ', '—É—Ç–µ—Ä—è/–∫—Ä–∞–∂–∞ –∫–∞—Ä—Ç—ã']

#–≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä
tfidf = joblib.load('model/tfidf.pkl')

#—Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
model_1 = load_model1('model/model1.cbm')

#—Å—Ç–æ–ø —Ç–µ–º—ã
model_2 = load_model1('model/model2.cbm')


df, data=load_file('data/–ì–∞–∑–ø—Ä–æ–º_valid.xlsx')

############################################################################
# –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
############################################################################


X_tfidf = tfidf_featuring(tfidf, data['clean'])

valid_predict1 = model_1.predict(X_tfidf)
valid_predict2 = model_2.predict(X_tfidf)

t = pd.DataFrame(valid_predict2, columns=stop_theme, index = list(data['‚Ññ –¥–∏–∞–ª–æ–≥–∞']))
t['–°—Ç–æ–ø —Ç–µ–º—ã']=t.astype(int).dot(t.columns+',').str[:-1]
t['‚Ññ –¥–∏–∞–ª–æ–≥–∞']=t.index
t['–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å']=valid_predict1
t['–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å']=t['–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å'].map({1:'positive', 0: "neutral", -1:'negative'})

num = 9

st.write("–î–∏–∞–ª–æ–≥")
st.write(df[df['‚Ññ –¥–∏–∞–ª–æ–≥–∞']==num][['‚Ññ —Å–æ–æ–±—â–µ–Ω–∏—è', '–¢–µ–∫—Å—Ç', '–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ']])

st.write("–ü—Ä–æ–≥–Ω–æ–∑")
st.write(t[t['‚Ññ –¥–∏–∞–ª–æ–≥–∞']==num][['–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å', '–°—Ç–æ–ø —Ç–µ–º—ã']]) 
